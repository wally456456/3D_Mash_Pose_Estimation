# 논문명 : Out-of-Domain Human Mesh Reconstruction via Dynamic  Bilevel  Online  Adaptation(2022-02-07 기준 SOTA)

### 저자명 : Shanyan  Guan,  Jingwei  Xu,  Michelle  Z.  He,  Yunbo  Wang,  Bingbing  Ni,  Xiaokang  Yang


### 모르는 단어 : asynchronously(때가 맞지 않게)


# Abstract
- 기존 SMPL 모델은 `카메라 파라메터`, `뼈의 길이`, `배경`, `가림 현상` 때문에 좋은 성능을 얻지 못했다
- 저자들은 위의 현상들을 `Online Adaption`을 통해서 해결하였다
- 저자들이 `Online Adaption`을 진행하면서 겪은 2가지 Challenging Problems
	- 1. 3D Annotation의 부족이 모델 훈련의 난이도를 높이고 3D 차원의 모호성을 높였다
	- 2. non-stationary한 데이터의 분포, 즉 기존의 `일반적인 데이터`로 학습한 모델이 `가림 현상 혹은 비정상적인 자세`를 취하고 있는 데이터에 대한 예측의 질을 떨어뜨린다

- DynaBOA는 시간적 제약을 활용하여 얻을 수 없는(예 : 가려진) 3D annotation들을 보상해주고 2가지 단계로 구성된 최적화를 통해서 다중 객체의 충돌을 피하게 해준다
- DynaBOA는 `3D Guidance`를 통해서 Distribution Shift시켜 주어 비슷한 source example들을 모델에 공동 훈련시켜준다(Retrieval 업무를 진행해 준다)
- DynaBOA는 다양한 optimization 단계를 하나의 Frame에 사용하여 fit를 시켜 줌으로 해서 overfitting을 피해주었다

# Introduction
-  ![plot](https://user-images.githubusercontent.com/69032315/154284491-699a35b8-4d77-49c9-be04-0dcb127e1947.png)

- 위의 사진에서 알 수 있듯이 데이터셋의 Domain Gap(데이터 셋의 획득 환경)이 다름으로 해서 `Distribution Shift`가 일어난다
- 저자들은 위와 같은 형상을 해결하기 위해서 test 구간에서 online으로 adapting하는 과정을 제시하였다
	- Key Insight는 라벨링이 되지 않은 데이터라도 모델의 bias(Distribution Shift)를 교정할 수 있는 시각적 정보를 제공해 줄 수 있다는 것이다

- Online Adapting Framework의 두가지 Challenges
	- 1. Test Data의 3D annotation의 부족이 Inference를 할 때 Training 난이도를 높인다
	- 2. Online Adaption은 hard sample들의 streaming test domain 환경이 빠르게 변화하면 영향을 많이 받는 다는 것

### 3.2 Online Adaption Framework
- 사전 학습된 모델![plot](https://user-images.githubusercontent.com/69032315/154284538-669edd85-f168-4758-9338-ca02e8ceb375.png) 을 Inference 단계에서 Unsupervised Learning 방식으로 Domain에 적응 시켜준다

# Approach
- ![plot](https://user-images.githubusercontent.com/69032315/154284577-b4b72f78-63e4-4f02-a49f-8a944a50fee1.png)


### 4.1 Bilevel Optimization with Space-Time Constraints
- Frame-wise `Shape and Pose` Constraints를 고려하는 ![plot](https://user-images.githubusercontent.com/69032315/154284670-3267be11-4adc-4a56-aa13-8fde32da202c.png)  와 시간적 일치성을 고려하는![plot](https://user-images.githubusercontent.com/69032315/154284641-2309837d-90f0-436b-85fa-026222931aaf.png) 를 각각의 단계에서 진행시켜준다 -> Bilevel Optimization
- 두 제약조건을 동시에 사용하게 되면 서로 상충하는 관계에 있기 때문에 한번에 사용하지 않는다

#### 4.1.1 Lower-Level Weight Probe
- Frame 하나의 `Shape 와 Pose` Constraints를 활용하는 부분
-  ![plot](https://user-images.githubusercontent.com/69032315/154284696-4be5a070-ef3d-4847-a9d8-e8c4fb945968.png)
- 첫번째 부분 = re-projection error of key points, 두번째 부분 = 3D human mesh reconstruction에서 관행적으로 사용되는 좌표들과 얼마나 차이가 있는가(너무 튀는 값이 나오면 억제하기 위해서)

#### 4.1.2 Upper-Level Weight Update
- 전반적인 시공간적 특성(동영상이 같은 시퀀스 데이터의 특성)을 이용하여 Adaption 시켜주는 부분

- ![plot](https://user-images.githubusercontent.com/69032315/154284752-9081c47b-07b0-4244-8b92-56c9a4452ed7.png) 
- r = 시간적 interval,  -> 즉 조금의 시간이 변했는데 많은 joint의 변화가 있었다면 억제해주는 느낌(Dependency 때문에)

-  ![plot](https://user-images.githubusercontent.com/69032315/154284776-66949f28-8285-4299-9a28-4e9f2cc9fbf1.png)
-  ![plot](https://user-images.githubusercontent.com/69032315/154284795-779b1213-1584-4b42-bd1e-dd68b6792036.png)(Teacher Model) = 이전 파라메터들의 지수평균을 이용하여 얻은 모델

- 즉 Motion 부분은 비교적 짧은 시간의 움직임을 Teacher부분은 장기적인 움직임을 제약해주기 위한 것이라고 할 수 있음
- 최종적인 Temporal Loss Term
-  ![plot](https://user-images.githubusercontent.com/69032315/154284807-ed13ce17-4212-44d8-bbaa-63e1f9e11f67.png)



#### 4.2 3D Exemplar Guidance
- ![plot](https://user-images.githubusercontent.com/69032315/154284862-aaec2ed0-e9fd-4496-b97b-1bbad9aa7f05.png)
- Retrieval Method를 이용함
- 2가지의 Processing 단계가 이루어짐
- 1. Offline Processing stage
	- Source Model  ![plot](https://user-images.githubusercontent.com/69032315/154284881-6dc3af77-e492-4f15-bc75-546ef11926d0.png)의 인코더 부분 ![plot](https://user-images.githubusercontent.com/69032315/154284900-1f13b3a1-27c4-4ccc-a9f1-abcdb73a85b0.png) 를 활용하여 source feature ![plot](https://user-images.githubusercontent.com/69032315/154284933-120f03ac-3ab2-47fd-8b92-43c972a01bf9.png) ![plot](https://user-images.githubusercontent.com/69032315/154284956-1dab8e83-b966-446c-bf74-1b415cff2871.png)  를 얻어 낸다
	- ![plot](https://user-images.githubusercontent.com/69032315/154284973-9f74b53f-5b0d-41cd-a915-497e5f57f95a.png)  = source data의 숫자,  ![plot](https://user-images.githubusercontent.com/69032315/154285011-1319d6cc-eb7f-409c-8127-9b5ebd662edd.png) = j 번째 사진의 feature 
	- 모든 feature를 다 맵핑하는 것은 Cost가 많이 들기 때문에 spherical K-Means를 활용한다, ![plot](https://user-images.githubusercontent.com/69032315/154285035-2ee9f91e-d588-49c7-8d4e-0db13ad955c3.png) (Cluster’s Center)
	- Kmeans 이후 각 군집에서 소수의 Feature들만 Sampling을 해준 후 해당 Source Image와 비교하여  ![plot](https://user-images.githubusercontent.com/69032315/154285060-28e3f4be-138c-4fae-8cfb-10f2fede8670.png)를 구성한다

- 2. Online Retrieval Stage
	- ![plot](https://user-images.githubusercontent.com/69032315/154285084-9454931a-b9c1-4dd4-b623-2591adbde035.png) = Query image에서 얻은 Feature

	- 앞서 만들어 놓았던 모든 군집과 코사인 유사도를 구해서 가장 가까운 군집 ![plot](https://user-images.githubusercontent.com/69032315/154285154-1a11dcff-0e99-4ac3-8f4a-a93b0860d3c7.png)을 찾아줌
	- ![plot](https://user-images.githubusercontent.com/69032315/154285171-3629ecb9-a170-4d24-8840-9893c67d0629.png) (|| . || = L-2Norm)
	- 이 후 해당 군집에서 K개의 sample들 ![plot](https://user-images.githubusercontent.com/69032315/154285202-39f6386a-7a80-4bcb-b0ee-142f95db2720.png)을 뽑아서 다음과 같은 loss function에 대입시켜준다
	-  ![plot](https://user-images.githubusercontent.com/69032315/154285209-123de256-f5c9-48b6-bf41-c2e996a434f8.png)

#### 4.3 Dynamic Update Strategy
- 핵심 아이디어는 모델이 이전에 test distribution에 위반되는 상황에서 빠르게 배워야 한다는 것이다(동영상에서 장면 전환 같은 경우), 그리고 일반적인 프레임에서는 적게 학습해야 한다는 것이다


- 절차
	- 한번의 bilevel adaption이 진행된 다음의 이번 이미지의 값과 그 전의 이미지의 값의 코사인 유사도 ![plot](https://user-images.githubusercontent.com/69032315/154285267-1cc2e68f-3176-46ac-aeb9-cfdb695f3e30.png)를 구한 다음 dt가 특정 threshold를 넘는다면 두 값의 dt가 threshold보다 작아질 때 까지 계속 ![plot](https://user-images.githubusercontent.com/69032315/154285478-7cc45ffc-857b-4342-8302-eed5c85faf37.png) 를 정제한다 (1-Sim 이기 때문에 두개가 유사하지 않다는 이야기이고 유사하지 않기 때문에 weight를 많이 update시켜서 다른 distribution에도 적응하게 한다)

















