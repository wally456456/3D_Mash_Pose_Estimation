# 논문명 : Collaborative Regression of Expressive Bodies using Moderation
### 저자명 : Yao Feng, Vasileios Choutas, Timo Bolkart, Dimitrios Tzionas, Michael J. Black
#### 3D Body Mesh SOTA 논문입니다

# Abstract

- Body에 대한 예측은 뛰어나지만 얼굴에 대한 예측은 성능이 좋지 않다
- PIXIE의 두가지 특징
	- 1. 얼굴과 몸에 대한 예측이 따로 하는 경향이 있지만 PIXIE는 두개를 함께 고려한다
	- 2. 성별에 대한 고려를 한다


# Introduction

- 각 신체부위에 confidence를 부여해서 각 feature에 가중치를 준다
- 모델이 학습과정에서 implicitly 하게 성별을 예측하게 하여 inference를 할 때는 gender label이 없어도 gender의 특성을 고려한 body shape를 추론할 수 있다
- face expert에 facial albedo와 3D facial-surface displacement를 추측하는 branches를 추가해주었다


# Method
- SMPL-X를 사용해서 하나의 RGB image로부터 body mesh를 만들어낸다
- Body, Face/head, hand regression 모델 3개를 사용한다
- 3가지 새로운 점
	- 1. 각 모델의 feature를 결합하고 confidence 스코어로 weight시켜주어 모호한 부분에 대한 추론을 잘하게 해주는 moderator를 만들었다
	- 2. 성별을 추론할 수 있게 하는 shape loss를 사용한다
	- 3. Face expert(Face의 parameter를 예측하는 모델)에서 얻은 albedo에 surface detail branch를 추가해 주었다

- Expressive 3D Body Model
	- SMPL-X를 사용해 주었다(body shape + facial expression + finger)
		- SMPL-X 의 함수 : ![plot](https://user-images.githubusercontent.com/69032315/148206422-b41a2af9-0d07-4f39-969f-36b6cdc6ed77.png)
 , β = shape, θ = pose,  ![plot](https://user-images.githubusercontent.com/69032315/148206428-6d682430-6d57-4557-9c5e-74479a88e5da.png)
= expression
		-  ![plot](https://user-images.githubusercontent.com/69032315/148206438-0c1c010e-1bb2-452a-8ea7-065a99dcbd79.png)
 = coefficients of a linear shape space <- body, 얼굴, 손의 shape correlation을 의미하는 관절 shape공간
		- ![plot](https://user-images.githubusercontent.com/69032315/148206453-1b37fa58-fa1b-4011-9eb0-1e0f145a66af.png)
 = coefficient of a low-dimensional linear space(얼굴의 expression)
		- θ = body, jaw(턱), hand pose의 vector -> 턱을 제외한 각 관절의 rotation은 6D vector로 인코딩 되어있다, 턱은 오일러 각을 이용해서 3차원의 vector로 인코딩
		- posed joint를 ![plot](https://user-images.githubusercontent.com/69032315/148206467-ed2aab24-3d04-4b95-9c36-0ecc15fca88d.png)
 로 표현한다 , J = 55
	- Camera : weak-perspective camera 모델을 스케일 vector인 ![image](https://user-images.githubusercontent.com/69032315/148206480-bcc9c348-25ff-4377-8e61-a6a2f04c7439.png)
 과 translation ![plot](https://user-images.githubusercontent.com/69032315/148206494-7051800c-21dc-4274-85d4-9815f985181c.png)
 를 사용해서 SMPL-X 를 이미지로부터 재건한다
	- X(joints), M(model vertices)는 ![plot](https://user-images.githubusercontent.com/69032315/148206512-243f65b1-040a-4fb1-9b65-89c216c17938.png)
 로부터 투영된 값이다

- PIXIE Architecture
  - ![plot](https://user-images.githubusercontent.com/69032315/148206543-04553362-02ff-4fb4-9aec-811fb29ec589.png)

	- Input images : I(image)에 bounding box를 사용해서 body를 뽑아내고 attention mechanism을 사용해서 face/head부분![plot](https://user-images.githubusercontent.com/69032315/148206581-b684b325-921d-44c1-b6eb-0404e0d2d1c6.png)과 손 부분인 ![plot](https://user-images.githubusercontent.com/69032315/148206598-c394e7e9-b8ca-440b-858a-d1fea027b9e3.png)
를 추출한다
	- Feature encoding : 각 추출한 이미지들을 인코더 ![plot](https://user-images.githubusercontent.com/69032315/148206658-24586821-8432-467e-afdd-c90b584712f2.png)
에 넣어주어 feature ![plot](https://user-images.githubusercontent.com/69032315/148206668-63010d33-fc18-4acd-bb24-fc3b4c11f085.png)
 를 추출해준다
		- face/head, hand 인코더로는 ResNet-50 을 사용하여 ![plot](https://user-images.githubusercontent.com/69032315/148206677-f7f7bb93-de92-4f0d-8dc8-421a04f0a41e.png)
 의 백터를 만든다
		- Body expert 인코더로는 HRNet을 사용해주어 ![plot](https://user-images.githubusercontent.com/69032315/148206687-39399d23-65d8-4b22-930c-ae8c1977e4d2.png)
 의 백터를 만든다

- Feature fusion(moderator) 
	- {body,head}, {body,hand} 쌍의 feature map들을 중재해주는 moderator ![plot](https://user-images.githubusercontent.com/69032315/148206738-e933dea1-13e5-4534-98fc-9b4f15769e33.png)
 를 사용하여 결합된 feature 인 ![plot](https://user-images.githubusercontent.com/69032315/148206751-19738d7c-ece2-4eac-bba5-f61e33f733a6.png)
 를 만들어낸다 -> 만들어진 결합된 feature를 ![plot](https://user-images.githubusercontent.com/69032315/148206765-16d80c6a-5804-409e-a6d6-8970aeff6c7b.png)
 (face/head, hand regressor)에 넣어준다(Moderator는 MLP로 구성 되어있고  ![plot](https://user-images.githubusercontent.com/69032315/148206775-5195dbee-c6db-4c41-ae6c-1990292da5bd.png)
(body)와  (face/head, hand)의 가중치들을 weighted sum하게 해준다)
 
	-   = part moderator,   = expert’s confidence,  = body feature,  = body 인코더와 moderator 사이의 linear 층, ,t = learned temperature weight(갱신되지 않음), 


	- Parameter regression 
	- 1.  (regressors)를  (moderator 를 거치지 않은)값들 만을 사용하는 경우
		-  는 카메라 parameter  과 머리와 손목을 제외한 body rotation과 포즈 를 infer한다 
		-  는 카메라 parameter  , face albedo  , lighting  를 infer한다 
		-  는 카메라 파라메터  를 추론한다

	- 2.  , 를 결합된 feature  , 에 사용한다
		-  는  (손목)와  (손가락)을 infer한다


























