# 논문명 : Pose2Mesh Graph Convolutional Network for 3D Human Pose and Mesh Recovery from a 2D Human Pose(2020 ECCV)

### 저자 : Hongsuk Choi, Gyeongsik Moon, Kyoung Mu Lee

# Abstract
- 기존 연구 방법론들은 SMPL같은 모델을 사용하기 때문에 SMPL이 학습될 당시의 상황과 다른 환경에서의 데이터는 예측하기가 힘들다
- 기존 연구는 3D rotation때문에 pose parameter를 추측하는 것이 어렵다
- 저자들은 2D human pose에서 직접적으로 Graph CNN을 사용해서 3D human mesh vertices를 뽑아낸다


# Introduction
- 저자들의 Approach의 이점
	- 1. Wild, Controlled Environment에서 2D pose의 상대적으로 모호한 geometric property를 파악할 수 있다(두 도메인의 차이 뿐만 아니라 본질적인 인간의 부위를 설명하는 Geometric한 정보를 얻을 수 있다)
	- 2, Pose2Mesh의 방법론은 Graph CNN을 이용하여 pose parameter가 필요하지 않다는 것이다
- PoseNet과 MeshNet으로 구성으로 되어있다 
	- PoseNet : 2D human pose를 3D human pose롤 lift 해준다
	- MeshNet : 2D와 3D pose 모두를 사용하여 3D human mesh를 coarse-to-fine manner로 추측하여 준다
		- coarse-to-fine : 초반에는 대략적인 업무를 하고 작업이 진행될수록 세밀하게 업무를 진행하는 것


# Related Work
- 3D human body and hand pose and mesh estimation
	- 저자들은 Pose2Mesh기법을 사용한다 -> 2D 이미지를 input으로 하고 3D Annotation이 된 데이터에도 사용할 수 있고 domain gap issue를 피해갈 수 있다

- GraphCNN for mesh processing
	- 단순히 fully-connected layer를 쌓는 것 보다 mesh topology 정보를 더 많이 추출할 수 있다

![plot](https://user-images.githubusercontent.com/69032315/148203106-762f7ab7-8177-4223-a53d-7a857f328c70.png)

# PoseNet
- Synthesizing errors on the input 2D pose
	- PoseNet은 root joint-relative 3D pose ![plot](https://user-images.githubusercontent.com/69032315/148203145-3f47be80-d08a-4684-9ffe-00fdcf39f617.png) 를 2D pose에서부터 추측을 한다 
		- J = number of human joints
	- 인간의 body를 pelvis(골반)로 , 인간의 손을 wrist(손목) root로 하는 root joint를 지정한다
	- error에 robust하게 만들기 위해서 2D input에 realistic error를 훈련 과정에서 더해준다 
	- 모델이 estimate한 2D pose or synthesized 2D pose를 ![plot](https://user-images.githubusercontent.com/69032315/148203208-35e178b2-2753-4916-92d6-2a49c1363e58.png)
 로 정의함

- 2D input pose normalization
	- ![plot](https://user-images.githubusercontent.com/69032315/148203253-45859251-3628-4770-bd64-e23614c0e67e.png)
 에 standard normalization을 적용해준다, ![image](https://user-images.githubusercontent.com/69032315/148203266-e238a304-a484-4ec8-9e08-0b655410f1d3.png)
 = standard normalization을 적용한 값
	- ![plot](https://user-images.githubusercontent.com/69032315/148203281-b742c142-ec1b-462e-9e3b-58d7935e960f.png)
 의 mean과 std는 피사체의 2D location과 scale을 의미한다
	- Normalization은 ![plot](https://user-images.githubusercontent.com/69032315/148203291-b71b8c09-6fa5-4843-91f3-77d5f78d3f93.png)
 가 2D였을 떄 와의 scale 과 location에 독립적이기 때문에 필요하다
- Network architecture
	- ![plot](https://user-images.githubusercontent.com/69032315/148203306-90faa92f-481f-4f13-9fc6-391d461c4f69.png)
 는 FC 층을 통해서 4096-dimensional feature vector가 된다 ->![plot](https://user-images.githubusercontent.com/69032315/148203322-cdb70b08-2365-408b-8bb8-6c7b5a9c647a.png)
 2개의 residual block에 들어간다 ->  를 대표하는 3J-dimensional vector가 FC layer를 통해서 만들어진다 

- Loss function
	- 3D pose ![plot](https://user-images.githubusercontent.com/69032315/148203337-4a1bf792-1b13-4367-90b9-29015b98a2b5.png)
 (예측한 값)과 실제 값의 L1 거리를 최소화하는 방향으로 학습을 함
 
 ![plot](https://user-images.githubusercontent.com/69032315/148203347-91439792-c3cb-4de9-b515-c75954b39065.png)


# MeshNet
 ![plot](https://user-images.githubusercontent.com/69032315/148203438-71cf4d36-4ac0-4001-b92b-816f88d91c84.png)

- Graph convolution on pose
	- Meshnet은 ![plot](https://user-images.githubusercontent.com/69032315/148203481-12b4ca54-950b-4317-824d-d6c56ecd0aa2.png)![image](https://user-images.githubusercontent.com/69032315/148203487-75db7807-3c83-4842-b22b-c64a788a04fc.png)

 을  로 concat 시켜준다(2차원과 3차원의 값을 합쳐준 것이기 때문에 5차원) -> Root joint-relative 3D Mesh  ![image](https://user-images.githubusercontent.com/69032315/148203524-c98339b6-999e-469a-a6d2-c09bfd61fdeb.png)
를 P로부터 예측한다 -> Spectral graph convolution을 이용한다
		- V = mesh vertices의 개수
		- Spectral graph convolution = Multiplication of ![image](https://user-images.githubusercontent.com/69032315/148203548-ee0c9ba9-ffc9-4793-8cda-ff09b1faf5a9.png)
  with a filter ![plot](https://user-images.githubusercontent.com/69032315/148203575-5bba5573-0672-4f0c-a270-54428ef0c7b6.png)
 in Fourier domain
		- Fourier domain :  ![plot](https://user-images.githubusercontent.com/69032315/148203585-52fe5ad6-a4b9-4fb1-9ab4-4155bce08e7d.png)

   - U = eigenvectors of normalized graph Laplacian L![plot](https://user-images.githubusercontent.com/69032315/148203650-2f98bc2e-c2ed-4b45-b3ab-dd8b177368b6.png),   = graph Fourier transform of x, 
	- MeshNet의 복잡성을 줄이기 위해서 Chebysev spectral graph convolution을 사용해 주었다

- ※ Spectral graph convolution 
	- GNN = graph 구조를 유지하면서 node 간의 message passing을 통해 node 또는 edge의 표현을 학습하는 신경망
	- spatial-based GNN은 이웃 노드에 대한 정보만 반영함
	- Spectral-based GNN은 eigen-decomposition을 적용하여 더 많은 정보를 반영 하지만 새로운 graph에 대해서 일반화 X
	- Graph Convolution은 노드와 연결된 이웃들의 정보를 weighted average함
	- Signal processing : 시간 또는 공간에 대해 변화하는 정보를 바꾸거나 분석하는 어떠한 연산
	- Graph signal processing : 신호 처리를 graph domain으로 확장한 것
	- Graph Laplacian(Laplacian Matrix) : 그래프의 유용한 특성을 찾는데 많이 사용됨, 이웃의 노드에 대한 차이를 구함

- ![plot](https://user-images.githubusercontent.com/69032315/148203823-eba5ebbe-edae-4a9d-9092-512132b8c89f.png) (Laplacian Matrix decomposition)

	- Fourier Transform : 임의의 입력 신호를 다양한 주파수를 갖는 주기함수들의 합으로 분해하여 표현하는 것
	- 쉽게 이해해서 4가지의 단계로 나눌 수 있음
		- 1. Feature propagation
			- 이웃 노드들에 의한 smoothing 된 hidden representation을 얻게 됨
		- 2. Linear transformation
			- 일반적인 MLP와 동일하게 가중치 파라메터 세타를 곱해줌
		- 3. Nonlinear transition
			- Relu와 같은 활성화 함수를 적용하여 k-th GCN layer의 feature representation을 구함
		- 4. Classifier
			- 마지막 GCN layer에 softmax함수를 적용

- Graph construction
	- Graph P를 만들어 주는 방법
	- ![plot](https://user-images.githubusercontent.com/69032315/148204053-796f5adf-0b5a-4d0e-aaac-f81e816cf807.png)
 , where ![plot](https://user-images.githubusercontent.com/69032315/148204097-49407b5b-384c-434d-b318-91da158f5c9a.png)![image](https://user-images.githubusercontent.com/69032315/148204110-af4a35e6-2d83-47f4-8aeb-281288133167.png)

  , J = human joints,![plot](https://user-images.githubusercontent.com/69032315/148204219-48a82e17-d978-4931-ad5f-d5ab8165c367.png)

   = adjacency matrix(인접 행렬)(인간의 skeleton과 symmetrical(대칭적인) 관계를 기반으로 joint간의 edge connection을 정의해준다)
		- 관절 i와 j가 같거나 연결되어 있다면 ![plot](https://user-images.githubusercontent.com/69032315/148204248-0683580a-e421-4fcb-b09c-0188cdf095b7.png)


- Normalized Laplacian =   where  
		- ![plot](https://user-images.githubusercontent.com/69032315/148204301-86879f63-cfae-40db-bace-bb8c041dadb0.png)  =Identity matrix, Dp = diagonal matrix(degree of each joint in Vp)
	- Scaled Laplacian  ![plot](https://user-images.githubusercontent.com/69032315/148204322-2ddc467c-4337-46b7-9a50-7e4c2f9e78d5.png)

- Spectral convolution on Graph
	- Gp에 spectral graph convolution을 적용시켜 준다
	-  ![plot](https://user-images.githubusercontent.com/69032315/148204533-481a8bb0-32ae-4036-8676-3bbe86cb5409.png)
		-  ![plot](https://user-images.githubusercontent.com/69032315/148204555-a3596557-b2d0-40e0-8a9b-591c49a3a31a.png)
 = Input, Output feature maps respectively,
		-  ![plot](https://user-images.githubusercontent.com/69032315/148204566-3cf80d51-f821-4b59-82ae-759bd07cb4f8.png)
  = Chebysev polynomial of order k, 
		-  ![plot](https://user-images.githubusercontent.com/69032315/148204575-08ac72b8-b9d5-4afe-912c-6a45c096108f.png)
 = Chebysev coefficient matrix(Graph convolution layer를 통해서 학습가능한 파라메터), 
		- K = Graph convolution에 몇 개의 인접한 노드를 고려할 것인가를 정해주는 것이고 저자들의 모델에서는 3의 값을 사용한다

- Coarse-to-fine mesh Upsampling
	- 점진적으로 Gp를 graph M으로 Upsampling시켜준다
		-   ![plot](https://user-images.githubusercontent.com/69032315/148204603-6e71e210-1f86-4afb-af79-c6d0613e76f1.png)![image](https://user-images.githubusercontent.com/69032315/148204624-13c429ad-e3a6-445a-a680-6be538b86939.png)
		-  ![plot](https://user-images.githubusercontent.com/69032315/148204645-5448bf24-5d5c-4039-b0c1-a8a02b19b2ad.png)
 = V human의 mesh vertices, ![image](https://user-images.githubusercontent.com/69032315/148204658-94440d06-b8a0-451e-823f-642043c17af5.png)
  = adjacency matrix defining edges of the human mesh
	- 그 후 graph coarsening 기술을 ![plot](https://user-images.githubusercontent.com/69032315/148204677-fc59f789-a8f6-4bd9-b5e7-571147317a38.png)
  에 적용시켜주어 다양한 그래프의 resolution ![plot](https://user-images.githubusercontent.com/69032315/148204692-af16ed7b-fed2-4a6f-ad3a-e3acc02069d0.png)
 을 구한다(C = number of coarsening step)

![plot](https://user-images.githubusercontent.com/69032315/148204707-36cb717b-6461-4744-b87f-c0842a866cc2.png)

  - Fig 2 는 coarsening process와 balanced binary tree structure of mesh graphs를 보여준다 
			- ![plot](https://user-images.githubusercontent.com/69032315/148204817-5c911a12-cbde-4199-9f43-0879b5be1327.png)
 의 i번째 vertex는 ![plot](https://user-images.githubusercontent.com/69032315/148204824-f4027745-01ab-4ede-8181-0d844545f383.png)
 의 node 2i-1번째와 2i번째의 부모 node이다 즉 node를 반으로 줄여 나가는 작업을 해주는 것

	- MeshNet의 마지막 output은 ![image](https://user-images.githubusercontent.com/69032315/148204834-c0032a01-12f9-470f-abf0-3067faa06c14.png)
 ( ![plot](https://user-images.githubusercontent.com/69032315/148204847-086003c2-67fc-4614-b6cf-07eb6ba30791.png)
을 사전에 정의된 indices 매핑을 적용해준 값)
	- MeshNet은 Gp를 reshaping과 FC layer를 사용하여 가장 coarest한 그래프인 ![image](https://user-images.githubusercontent.com/69032315/148204861-7cfb821e-be9e-48a9-8ca6-ba305eebbdeb.png)
 로 만든다 -> 다음 수식과 같은 Spectral graph convolution을 각 resolution의 mesh graph에 적용해준다
 - ![plot](https://user-images.githubusercontent.com/69032315/148204871-0e1f19f0-9a41-4164-a8d6-efb8f9a4edb9.png)

	-  ![plot](https://user-images.githubusercontent.com/69032315/148204884-1212add2-f765-4d10-950b-1eb52b6ba620.png), 다른 값들은 Eq3번과 같다
	- Mesh upsampling을 각 부모 vertex인  의 feature를 복사하는 방식으로 자녀 vertices ![image](https://user-images.githubusercontent.com/69032315/148204911-7679036a-3332-48fa-8ab6-cfe373eddc7c.png)
 값을 얻어낸다, Upsampling 과정은 다음 식과 같이 정의 된다
 
![plot](https://user-images.githubusercontent.com/69032315/148204920-afae9c3d-3b2a-4c7f-b79c-bc8a548f00eb.png)

-  ![plot](https://user-images.githubusercontent.com/69032315/148204963-cc4c5610-2574-4f91-87e9-0f83ff64e28b.png)
는 ![plot](https://user-images.githubusercontent.com/69032315/148204979-456883aa-141a-4f8d-99ae-512197307d61.png)
 의 feature map이다, ![plot](https://user-images.githubusercontent.com/69032315/148205005-db174923-82b2-4fe6-ac27-bfd6decde5cd.png)
  은  ![plot](https://user-images.githubusercontent.com/69032315/148205012-cdf4c3a4-0aec-49ca-9211-8112fe5bf521.png)
의 마지막 feature map이다
	-  ![plot](https://user-images.githubusercontent.com/69032315/148205019-9cdf9e6e-a49c-4efd-b0b0-75a7e393f674.png)
 는 Nearest-neighbor upsampling function, ![plot](https://user-images.githubusercontent.com/69032315/148205036-d83add18-a9be-49b7-a1c2-99aae1508103.png)
 는  ![plot](https://user-images.githubusercontent.com/69032315/148205045-92bf2fc4-7d36-4645-be0a-3167f9772d12.png)
의 vertices의 Feature 차원의 수이다
	
- 학습과정에서 저자들은 각 resolution 마다 residual connection을 진행해 주었다

- MeshNet Loss function	
	- 4가지의 loss function
	- 1. Vertex coordinate loss : 예측된 3D mesh coordinate M과 ground truth 값과의 L1 거리 차이
  -  ![plot](https://user-images.githubusercontent.com/69032315/148205067-ce8c7961-8b53-49bf-885e-23ef077ec5bc.png)

	- 2. Joint coordinate loss : M에서 예측된 3D pose 와 groundtruth root-relative 3d pose와의 L1 거리를 구하여 MeshNet이 joint location에 정열된 mesh vertices를 만들게 한다. 3D pose는 JM으로 정의되고  는 joint regression matrix이다
  - ![plot](https://user-images.githubusercontent.com/69032315/148205113-210348ab-0f00-4ef0-8ba8-5205b0cf003c.png)

	- 3. Surface normal loss : Output mesh의 표면의 vector들을 ground truth와 같게 하도록 하는 loss, surface를 smooth하고 디테일하게 만들어 준다
  - ![plot](https://user-images.githubusercontent.com/69032315/148205133-2d104a46-fa1e-400c-bb58-7c6c0c87d533.png)

	-  ![plot](https://user-images.githubusercontent.com/69032315/148205146-e9aed2b7-c5da-4ec6-b312-68dc6efb53be.png)
 = triangle face in human mesh, groundtruth unit normal vector of f
	-  ![plot](https://user-images.githubusercontent.com/69032315/148205166-ae00beaf-4efa-47d9-a08e-bd4b07ac27b7.png)
 = f의 i,j 번째 vertices
	- 4. Surface edge loss : 예측된 값과 ground-truth의 edge length loss를 구한다 -> 손,발,입과 같이 dense vertices 의 smoothness를 높이는데 효과적이다


















