# 논문명 : GolfDB:  A Video  Database  for  Golf Swing  Sequencing

### 저자명 : William  McNally, Kanav Vats, Tyler Pinto, Chris  Dulhanty, John  McPhee               Alexander Wong

모르는 단어 : torso-pelvic(몸통 모양의)

전문단어 : 



# Abstract
- GolfDB : 1400개의 골프 스윙 영상에 대한 데이터셋이다
- 각 프레임이 `어떤 상황인지`, Bounding Box, player name, 성별, 골프채의 유형, 시야의 유형이 라벨링이 되어있다
- SwingNet = 골프 스윙의 단계를 8개로 캡처해준다 -> 76.1%의 정확성, 8개 중 6개를 맞출 확률은 91.8%


# Introduction
- 골프 영상들은 유튜브에서 받아왔다

- 8 events in golf swing sequence
	- Top: face-on view. Bottom: down-the-line view. The names of the events from left to right are Address, Toe-up, Mid-backswing, Top, Mid- downswing, Impact, Mid-follow-through, and Finish



# GolfDB

- Video Collection
	- Shaft(골프채의 헤드와 그립 가운데 부분)이 보여야 하기 때문에 해상도가 높은 영상들만 사용하였다
	- PGA, LPGA, Champions Tours에 해당하는 선수들 248명의 골프 스윙을 수집하였다
	- 다양한 장소(페어웨이, 러프, 벙커, 티박스)에서 수집한 데이터이다
	- 30FPS, 720p resolution으로 수집되었다


- Annotation
	- Annotator들은 10프레임당 한 개의 annotation label을 부여해 주었다
	- 30FPS의 상황 때문에 정확하게 포즈의 순간을 Annotate 해주기 힘든 부분이 있어서 Annotator에게 최대한 가까운 프레임에 labeling해주라고 주문하였다
	- `Bounding box`, `club type`, `view type`, `slow-motion인지 real-time`인지에 대한 분류 등을 수행해 주었다
![plot](https://user-images.githubusercontent.com/69032315/149356534-af590b6c-62b3-493f-8075-8cc2dd1225d8.png)

- Evaluation Metric and Experimental Protocol
	- Tolerance ![plot](https://user-images.githubusercontent.com/69032315/149356603-02e84d0d-11f5-4e83-98d3-b1e689f2f16b.png) (Number of Frames) = 정확하게 event가 해당 프레임에 정확하게 발생하지 않아도  ![plot](https://user-images.githubusercontent.com/69032315/149356635-c20e5e2a-dcdb-4bec-ae19-410946b62fdd.png)프레임의 수 만큼 참아주겠다는 뜻 -> real-time의 데이터에는 값을 1로 사용하지만 slow-motion일 경우에는 달라진다
	- 따라서 저자들은 Address에서 Impact까지의 Frame의 수에 따라 slow-motion에서의 tolerance를 바꾸어 주는 방법론을 사용한다
		-  ![plot](https://user-images.githubusercontent.com/69032315/149356736-9f5105d4-03d6-43d4-a027-a5dbe4d2b2cd.png)
		- n = Address에서 Impact까지의 프레임의 수, f = sampling frequency, [ ] = round(반올림)


# SwingNet : A Swing Sequencing Network
- Network Architecture
	- MobileNetV2(모바일 환경에서의 빠른 실행을 위해)을 backbone으로 활용함
	- I = image, e = sequence of event probability
	- Sequence에서 8+1(No-event)의 종류를 가지고 있다
	- Backbone에서 얻은 Feature vector를 global average pooling을 적용시켜 얻은 값  f = ![plot](https://user-images.githubusercontent.com/69032315/149356674-beeea088-5b4b-42aa-bdcd-4a2a1c2ebcd3.png) 를 H개의 hidden unit을 가지고 있는 N층의 Bi-directional LSTM에 투입 시켜주고 FC-layer층을 거친 다음에 softmax를 사용해주어서 class의 probability 를 예측








